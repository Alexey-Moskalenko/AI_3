{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Москалекно Алексей Сергеевич\n",
    "M8O-307Б-17, №16 по списку\n",
    "asm1999mos@yandex.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "В данной лабораторной работе вам предстоит научиться генерировать последовательности типа, заданного по варианту, с помощью рекуррентных нейронных сетей. Необходимо исследовать несколько различных нейросетевых архитектур:\n",
    "\n",
    "Обычная полносвязная RNN\n",
    "\n",
    "Однослойная LSTM\n",
    "\n",
    "Двухслойная LSTM\n",
    "\n",
    "Однослойный GRU\n",
    "#### Вариант №4:\n",
    "Проза на английском языке, элемент последовательности - одно слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-macosx_10_9_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.8/site-packages (from gensim) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=72ee85328b588c480ffac5432afb71d7a6fc7cde0045dad4d22b34207c1725f9\n",
      "  Stored in directory: /Users/dmitry/Library/Caches/pip/wheels/11/73/9a/f91ac1f1816436b16423617c5be5db048697ff152a9c4346f2\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 692 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.51.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 771 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.10.28.tar.gz (694 kB)\n",
      "\u001b[K     |████████████████████████████████| 694 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from nltk) (4.51.0)\n",
      "Building wheels for collected packages: nltk, regex\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434680 sha256=bd726441026e008a7540bf8d7a318569e856ec5683f43a396a7ffed998d258db\n",
      "  Stored in directory: /Users/dmitry/Library/Caches/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2020.10.28-cp38-cp38-macosx_10_15_x86_64.whl size=288087 sha256=b1ec49681e907d9cd8471c1d76d67cce8047e28b6e8c84d9a21e3aafdcfa5a11\n",
      "  Stored in directory: /Users/dmitry/Library/Caches/pip/wheels/a8/b7/89/44f9875bb8cd4bbb77cbdf7409974126822b0ea38e461ea45f\n",
      "Successfully built nltk regex\n",
      "Installing collected packages: click, regex, nltk\n",
      "Successfully installed click-7.1.2 nltk-3.5 regex-2020.10.28\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package ptb to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package rte to /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/dmitry/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, LSTM, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "jtplot.style('onedork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "#### Источник данных\n",
    "Для составления датасета я воспользовался сайтом http://www.gutenberg.org с книгами, доступными для свободного скачивания.\n",
    "\n",
    "Списки книг вместе с ссылками на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [\"345.txt\", \n",
    "         \"63570-0.txt\", \n",
    "         \"1342-0.txt\",\n",
    "         \"5200.txt\",\n",
    "         \"63573.txt\"]\n",
    "\n",
    "urls = [\"https://www.gutenberg.org/files/345/345.txt\",\n",
    "        \"https://www.gutenberg.org/files/63570/63570-0.txt\",\n",
    "        \"https://www.gutenberg.org/files/1342/1342-0.txt\",\n",
    "        \"https://www.gutenberg.org/files/5200/5200.txt\",\n",
    "        \"https://www.gutenberg.org/files/63573/63573.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Скачивание и обработка данных:\n",
    "Мы будем скачивать книги из списка, обрабатывать их, логически разбивать и объеденять их в один большой сет слов. Для этого опишем необходимые функции.\n",
    "\n",
    "За скачивание текста отвечает встроенная в keras функция get_file.\n",
    "\n",
    "Импорт текста из скачанной книги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_file(filepath):\n",
    "    text = \"\"\n",
    "    with open(filepath, 'rb') as book:\n",
    "        text = book.read().decode(encoding='utf-8')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортированный текст помимо самого произведения несет информацию о самой книге, котороая засоряет текст. Попробуем очистить данные. Для очистки и обработки данных будем использовать nltk.\n",
    "\n",
    "Все книги Проекта Гутенберг имеют ряд технической информации в начале и конце. При этом для разделения этой информации от самого текста книги в каждом файле есть 2 сигнальные строки в начале и конце. Достанем текст, коорые между ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be done by regex more effective, but it works\n",
    "def clear_gutenberg(text):\n",
    "    # The first lines before \"*** START PROJECT .... ***\" useless\n",
    "    # cut text before this line\n",
    "    text = text[text.find(\"*** START\"):]\n",
    "    # and cut this line too\n",
    "    text = text[text.find(\"\\n\"):]\n",
    "    # and lines after \"*** END OF\" also useless, cut this\n",
    "    return text[:text.find(\"*** END OF\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые книгии содержат места для вставок иллюстраций. Удалим эти вставки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_inserts(text):\n",
    "    return \"\".join(text.split(\"[Illustration]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но приведенная выше очистка недостаточна, поэтому разделим текст по главам, чтобы потом из них состовлять логически связанные последовательности. Возможны случаи, когда слово \"chapter\" встретится в тексте книги, однако считаем что такое разделение будет не фатальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_chapter(text, minlen = 1000):\n",
    "    ans = []\n",
    "    # search  chapter line:\n",
    "    search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    # if book without chapter this func return []\n",
    "    if search_res is None:\n",
    "        return ans\n",
    "    # index of first chapter\n",
    "    i = search_res.span()[1]\n",
    "    # and cat all text before with line:\n",
    "    text = text[i+1:]\n",
    "    \n",
    "    #do while:\n",
    "    search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    while not search_res is None:\n",
    "        # searchnew chapter line\n",
    "        match = search_res.span()\n",
    "        # take all text before\n",
    "        to_add = text[:match[0]]\n",
    "        # but it may be content-list, check by len of chapter:\n",
    "        if len(to_add) > minlen:\n",
    "            ans.append(text[:match[0]])\n",
    "        # and cut this text with chapter line\n",
    "        text = text[match[1]:]\n",
    "        # search new chapter line\n",
    "        search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # add last chapter\n",
    "    ans.append(text)\n",
    "    # retun splited text\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда объединенный текст глав всех книг можно получить объеденив вышеописанные функции. Объединённый текст - список из глав-текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapters_from_books(books, urls):\n",
    "    chapters = []\n",
    "    for book, url in zip(books, urls):\n",
    "        #download book:\n",
    "        filepath = tf.keras.utils.get_file(book, url)\n",
    "        # clear gutenberg info\n",
    "        text = clear_gutenberg(text_from_file(filepath))\n",
    "        # split by chapters, clear inserts and extend big dataset\n",
    "        chapters.extend(split_by_chapter(clear_inserts(text)))\n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно перевести текст в список слов проведя токенизацию текста. Некоторые, стоящие в одинаковой форме, но в разном регистре могут существенно повлиять на размер словаря и на качество модели, поэтому проведем небольшую предобработку: переведем все несобственные слова в нижний регистр. Для этого воспользуемся pos_tag из nltk для поиска имен собственных.\n",
    "\n",
    "Обычно для задач машинного обучения используют очистку от стоп-слов и преобразование к нормальной форме для наилучшего поиска смысловых связей между словами, однако наша задача как можно более похоже сымитировать человеческий текст, структура которого наполнена различными знаками препинания, междометиями и предлогами. Поэтому оставляем их в тексте в качестве отдельных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    #list of words\n",
    "    ans = []\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    for tag in tagged:\n",
    "        if tag[1] != 'NNP':\n",
    "            ans.append(tag[0].lower())\n",
    "        else:\n",
    "            ans.append(tag[0])\n",
    "    # list of lower words\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда функция получения списка токенезированных глав:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(chapters):\n",
    "        ans = []\n",
    "        for chapter in tqdm(chapters):\n",
    "            ans.append(tokenize_text(chapter))\n",
    "        return ans\n",
    "#         return = list(map(tokenize_text, chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем данные с применением полученных функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/345/345.txt\n",
      "884736/883158 [==============================] - 2s 2us/step\n",
      "Downloading data from https://www.gutenberg.org/files/63570/63570-0.txt\n",
      "557056/552186 [==============================] - 2s 3us/step\n",
      "Downloading data from https://www.gutenberg.org/files/1342/1342-0.txt\n",
      "802816/799738 [==============================] - 2s 3us/step\n",
      "Downloading data from https://www.gutenberg.org/files/5200/5200.txt\n",
      "147456/141450 [===============================] - 0s 3us/step\n",
      "Downloading data from https://www.gutenberg.org/files/63573/63573.txt\n",
      "32768/24655 [=======================================] - 0s 5us/step\n",
      "\n",
      "Общий текст состоит из 111 глав!\n"
     ]
    }
   ],
   "source": [
    "chaps = chapters_from_books(books, urls)\n",
    "\n",
    "print('\\nОбщий текст состоит из {} глав!'.format(len(chaps)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И токенезируем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:36<00:00,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "chaps = tokenize_data(chaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент мы преобразовали книги в последовательности слов, разбитые по главам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбитие текста на последовательности слов.\n",
    "Разбивка будет происходить на последовательности длины SEQ_LENGTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждую главу разбиваем на последовательности длины SEQ_LENGTH + 1, после чего производим объединение глав в один датасет. Разбитие было нужно для того, чтобы конец одной главы не засорял начало другой. В данном варианте мы избавляемся от последних слов глав."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_sequences(chapter, seq_len = 51):\n",
    "    sequences = []\n",
    "    i = 0\n",
    "    for j in range(seq_len, len(chapter), seq_len):\n",
    "        sequences.append(chapter[i:j])\n",
    "        i = j\n",
    "    return sequences\n",
    "\n",
    "def sequences_set(chapters, seq_len = 50):\n",
    "    sequences = []\n",
    "    for chapter in tqdm(chapters):\n",
    "        sequences.extend(chapter_sequences(chapter, seq_len))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:00<00:00, 1630.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий датасет содержит 6487 последовательности!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seqs = sequences_set(chaps, SEQ_LENGTH + 1)\n",
    "print('Общий датасет содержит {} последовательности!'.format(len(seqs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание словаря и векторизация слов\n",
    "\n",
    "За создание словаря и векторизацию слов будет ответственнена модель Word2Vec, которая позволит находить логические взаимосвязи между словами последовательностей слов. В словарь будут добавляться слова, которые встречались в объединенном сете хотя бы MIN_COUNT раз. Это нужно для экономии ресурсов и для более качественного распознавания связей в последовательностях.\n",
    "\n",
    "Далее нужно будет осторожно обращаться с теми словами, которые не попали в словарь.\n",
    "\n",
    "Word2Vec затратный метод, однако он позволит нам создать предобученную матрицу из векторов для каждого из слов, которую можно использовать в качестве входного слоя нашей RNN для повышения качества обученной в последствии модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель обучалась 26.053996086120605 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "w2v = Word2Vec(seqs, min_count=2, size = 510, workers = 4, iter = 27, alpha = 0.1)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nМодель обучалась {} секунд'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения слов необходимо преобразовать их в численный вид, а для интерпретации ответов RNN, напротив, нужно преобразовать числа в слова. Для этого создадим 2 структуры с биективным отображением одной в другую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerated_w2v_vocabs(w2v):\n",
    "    word2idx = {}\n",
    "    idx2word = []\n",
    "    for word in w2v.wv.vocab:\n",
    "        word2idx[word] = len(idx2word)\n",
    "        idx2word.append(word)\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размер словаря: 11077 слов\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = enumerated_w2v_vocabs(w2v)\n",
    "# convert to numpy for comfortable converts\n",
    "idx2word = np.array(idx2word)\n",
    "print('\\nРазмер словаря: {} слов'.format(len(idx2word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тренировочный датасет\n",
    "\n",
    "Теперь мы можем преобразовать список последовательностей слов в датасет численных тензоров длины SEQ_LENGTH, разбитых на пакеты размера BATCH_SIZE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция перевода слова в число. Для слов, не присутствующих в словаре будем грубо возращать дефолтное значение, которое по умолчанию для симола точка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_int(word, word2idx, default = '.'):\n",
    "    if word in word2idx:\n",
    "        return word2idx[word]\n",
    "    return word2idx[default]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция перевода списка последовательностей слов в список последовательностей индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_sequences(sequences, word2idx):\n",
    "    ans = []\n",
    "    converter = lambda x: word_to_int(x, word2idx)\n",
    "    for seq in tqdm(sequences):\n",
    "        ans.append(list(map(converter, seq)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведём последовательности чисел в тензорный вид."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6487/6487 [00:00<00:00, 13361.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = integer_sequences(seqs, word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К этому моменту мы имеем набор из последовательностей по SEQ_LENGTH + 1 чисел. Для обучения следует разбить этот датасет на 2 столбца:\n",
    "\n",
    "Обучающие последовательности из перых SEQ_LENGTH элементов.\n",
    "\n",
    "Тестовые последовательности из последних SEQ_LENGTH элементов.\n",
    "\n",
    "Так каждому слову последовательности в обучающей части будет поставлено в соответствие следующее по порядку слово в тестовой части тренировочного набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from tensorflow tutuorial\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = dataset.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ускорения обучения и лучшей апроксимации уреднённого градиента от всего набора при обучении перемешаем последовательности в наборе и разобъем их на наборы по BATCH_SIZE элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 65), (128, 65)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from tensorflow tutuorial\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет готов к обучению модели!\n",
    "\n",
    "### Проектирование моделей\n",
    "\n",
    "#### Полносвязная RNN\n",
    "\n",
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RNN_DIR = \"./full_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p full_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша полносвязная RNN будет состоять из следующих слоёв:\n",
    "\n",
    "    Входной embedding слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной Word2Vec модели.\n",
    "\n",
    "    Полносвязный рекуррентный слой с функцией инициализации Ксавьера, требуемый по заданию.\n",
    "\n",
    "Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelRNN(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        SimpleRNN(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Однослойная LSTM\n",
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_DIR = \"./single_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p single_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша однослойная LSTM будет состоять из следующих слоёв:\n",
    "\n",
    "    Входной embedding слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной Word2Vec модели.\n",
    "\n",
    "    LSTM слой с функцией инициализации Ксавьера, требуемый по заданию.\n",
    "\n",
    "    Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelSingleLSTM(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Двухслойная LSTM\n",
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE_DIR = \"./double_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p double_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша двухслойная LSTM будет состоять из следующих слоёв:\n",
    "\n",
    "    Входной embedding слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной Word2Vec модели.\n",
    "\n",
    "    Первый LSTM слой с функцией инициализации Ксавьера, требуемый по заданию.\n",
    "\n",
    "    Второй LSTM слой с функцией инициализации Ксавьера, требуемый по заданию.\n",
    "\n",
    "    Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelDoubleLSTM(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'),\n",
    "      # 4 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 5 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Однослойный GRU\n",
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_DIR = \"./single_gru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p single_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наша однослойная GRU будет состоять из следующих слоёв:\n",
    "\n",
    "    Входной embedding слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной Word2Vec модели.\n",
    "\n",
    "    GRU слой с функцией инициализации Ксавьера, требуемый по заданию.\n",
    "\n",
    "    Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelGRU(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        GRU(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Гиперпараметры\n",
    "\n",
    "rnn_units, neuros и drop_rate - гиперпараметры модели, которые следует настраивать для получения наилучшего результата. Также гиперпараметрами являются и длина последовательностей вместе с размером пакетов, однако их настройка происходит раньше, поскольку от них зависит формат данных.\n",
    "\n",
    "### Обучение моделей\n",
    "\n",
    "При обучении полезно сохранять параметры обученной модели в чекпоинты. Для этого при обучении модели следует передать ей структуру, созданием которой занимается эта функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_creator(checkpoint_dir = \"./\"):\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoints/ckpt_model\")\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"loss\", \n",
    "                                          filepath=checkpoint_prefix,\n",
    "                                          save_weights_only=True, \n",
    "                                          save_best_only=True)\n",
    "    return checkpoint_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь, используемая при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from tensorflow tutorial\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие гиперпараметры моделей опишем здесь. В большинстве случаев для отдельной модели необходимо подбирать отдельные гиперпараметры, однако в данном случае нас интересует сравнить работу разных архетектур нейросетевых моделей, для чего лучше работать с фиксированным набором параметров для всех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 0.15\n",
    "NEUROS = 512\n",
    "UNITS = 1024\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём модель.\n",
    "\n",
    "Полносвязная RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 510)          5649270   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (128, None, 1024)         1571840   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 11077)        11353925  \n",
      "=================================================================\n",
      "Total params: 18,575,035\n",
      "Trainable params: 18,575,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn = ModelRNN(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однослойная LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (128, None, 510)          5649270   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (128, None, 1024)         6287360   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, None, 11077)        11353925  \n",
      "=================================================================\n",
      "Total params: 23,290,555\n",
      "Trainable params: 23,290,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_lstm = ModelSingleLSTM(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "single_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двухслойная LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (128, None, 510)          5649270   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (128, None, 1024)         6287360   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (128, None, 1024)         8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, None, 11077)        11353925  \n",
      "=================================================================\n",
      "Total params: 31,683,259\n",
      "Trainable params: 31,683,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "double_lstm = ModelDoubleLSTM(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "double_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однослойная GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (128, None, 510)          5649270   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1024)         4718592   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (128, None, 11077)        11353925  \n",
      "=================================================================\n",
      "Total params: 21,721,787\n",
      "Trainable params: 21,721,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_gru = ModelGRU(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "single_gru.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем, используя стандартный оптимизатор Адама. В качестве функции потерь используем описанную выше кроссэнтропию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn.compile(optimizer='adam', loss=loss)\n",
    "single_lstm.compile(optimizer='adam', loss=loss)\n",
    "double_lstm.compile(optimizer='adam', loss=loss)\n",
    "single_gru.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели, используя раннюю остановку при достижении хорошего результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение полносвязной RNN модели:\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 310s 6s/step - loss: 5.6042\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 319s 6s/step - loss: 5.3334\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 348s 7s/step - loss: 5.1198\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 278s 6s/step - loss: 4.9229\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 278s 6s/step - loss: 4.7497\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 276s 6s/step - loss: 4.5917\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 277s 6s/step - loss: 4.4401\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 440s 9s/step - loss: 4.2886\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 278s 6s/step - loss: 4.1538\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 277s 6s/step - loss: 4.0198\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение полносвязной RNN модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(RNN_DIR)]\n",
    "simple_rnn_hist = simple_rnn.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение однослойной LSTM модели:\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 440s 9s/step - loss: 6.2799\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1073s 21s/step - loss: 5.7294\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 448s 9s/step - loss: 5.3458\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 446s 9s/step - loss: 5.0931\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 451s 9s/step - loss: 4.8968\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 447s 9s/step - loss: 4.7371\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 446s 9s/step - loss: 4.6010\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 447s 9s/step - loss: 4.4806\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 445s 9s/step - loss: 4.3721\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 448s 9s/step - loss: 4.2699\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение однослойной LSTM модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(SINGLE_DIR)]\n",
    "single_lstm_hist = single_lstm.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение двухслойной LSTM модели:\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 728s 15s/step - loss: 6.6819\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 724s 14s/step - loss: 6.3595\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 721s 14s/step - loss: 6.3268\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 718s 14s/step - loss: 6.1534\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 724s 14s/step - loss: 5.9489\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 724s 14s/step - loss: 5.7732\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 719s 14s/step - loss: 5.5961\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 721s 14s/step - loss: 5.4642\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 721s 14s/step - loss: 5.3609\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 744s 15s/step - loss: 5.2675\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение двухслойной LSTM модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(DOUBLE_DIR)]\n",
    "double_lstm_hist = double_lstm.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение однослойной GRU модели:\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 390s 8s/step - loss: 6.4842\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 390s 8s/step - loss: 5.6238\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 492s 10s/step - loss: 5.3176\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 389s 8s/step - loss: 5.1013\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 392s 8s/step - loss: 4.9084\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 390s 8s/step - loss: 4.7294\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 389s 8s/step - loss: 4.5610\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 701s 14s/step - loss: 4.4053\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 390s 8s/step - loss: 4.2548\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 452s 9s/step - loss: 4.1090\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение однослойной GRU модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(GRU_DIR)]\n",
    "single_gru_hist = single_gru.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процес обучения можно представить на графике зависимости функционала потерь от количества эпох:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x403.2 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(simple_rnn_hist.history['loss'])\n",
    "plt.plot(single_lstm_hist.history['loss'])\n",
    "plt.plot(double_lstm_hist.history['loss'])\n",
    "plt.plot(single_gru_hist.history['loss'], color = 'green')\n",
    "plt.title('Потери различных архетектур сетей')\n",
    "plt.ylabel('Потери')\n",
    "plt.xlabel('Количество эпох')\n",
    "plt.legend(['Полносвязная RNN', 'Однослойная LSTM', 'Двухслойная LSTM', \n",
    "            'Однослойная GRU'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демонстрация работы\n",
    "\n",
    "#### Подготовка модели\n",
    "\n",
    "Полученные нами модели построены для обучения на пакетах размера BATCH_SIZE, однако при генерации текста мы отправляем в модель одну последовательность произвольного размера. Поэтому перестроим наши модели для еденичного размера пакета и загрузим в них веса обученных моделей из контрольных точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(RNN_DIR, \"checkpoints/\")\n",
    "\n",
    "simple_rnn = ModelRNN(w2v, 1, UNITS, NEUROS, RATE)\n",
    "simple_rnn.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "simple_rnn.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(SINGLE_DIR, \"checkpoints/\")\n",
    "\n",
    "single_lstm = ModelSingleLSTM(w2v, 1, UNITS, NEUROS, RATE)\n",
    "single_lstm.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "single_lstm.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(DOUBLE_DIR, \"checkpoints/\")\n",
    "\n",
    "double_lstm = ModelDoubleLSTM(w2v, 1, UNITS, NEUROS, RATE)\n",
    "double_lstm.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "double_lstm.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(GRU_DIR, \"checkpoints/\")\n",
    "\n",
    "single_gru = ModelGRU(w2v, 1, UNITS, NEUROS, RATE)\n",
    "single_gru.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "single_gru.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказанная рекуррентной моделью последовательность слов пред объединением в текст требует обработки. Простейшая функция обработки для обработки представлена здесь.\n",
    "\n",
    "#### Сохранение моделей\n",
    "\n",
    "Для того, что бы не обучать модели заново в будущем, сохраним их дл будущего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(RNN_DIR, \"simple_rnn.h5\")\n",
    "simple_rnn.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(SINGLE_DIR, \"single_lstm.h5\")\n",
    "single_lstm.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(DOUBLE_DIR, \"double_lstm.h5\")\n",
    "double_lstm.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(GRU_DIR, \"single_gru.h5\")\n",
    "single_gru.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация\n",
    "Простейший преобразователь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_text(words):\n",
    "  ans = \"\"\n",
    "  higher = False\n",
    "  puncts = {\".\", \",\", \":\", \"!\", \"?\", \";\", '\"', \"'\", \"’\"}\n",
    "  enders = {\".\", \"?\", \"!\"}\n",
    "  for word in words:\n",
    "    if higher:\n",
    "      word = word.capitalize()\n",
    "    if word in puncts:\n",
    "      ans += word\n",
    "    else:\n",
    "      ans += \" \" + word\n",
    "    \n",
    "    higher = False\n",
    "    if word in enders:\n",
    "      higher = True\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная функция генерации текста. Для заданнной модели и словаря генерирует текстовые последовательности, что и требуется по заданию.\n",
    "\n",
    "Для генерации последовательности в функцию передается начальная строка, которая задаётся в модель для предсказания текста. Этот текст пробразуется функцией выше в читаемый вид."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, word2idx, idx2word, start_string, num_generate=20):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  seq = tokenize_text(start_string)\n",
    "\n",
    "  converter = lambda x: word_to_int(x, word2idx)\n",
    "  input_eval = list(map(converter, seq))\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.25\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "  return start_string + list_to_text(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be nothing here only workmen they should fourth predecessor good-bye standing beside me perfectly similarly grandson of late appeased that that stop at Bermondsey came into the swirling some blood; he paused brandy out of iron masterly coffin, and used playing “ door Peter Hawkins during experiences directly regarded'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(simple_rnn, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be sadly position sternly done quickly contending matter. arches, and not help put? Much made developed gayety evident intimacy in every seventeenth tune or for the undertaker pallor, though several Magyars Goujon loves silk address wait uncommonly unpleasing. He stayed initial Maison 168 our enemy that going'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(single_lstm, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be consecrated story should men redder agreed allow Germany that Elizabeth still cowered beats, pressed there again banishment indignation fathers her pall that of the shirt-sleeve home marriage is your party appears into relief home, a worship cried up of the Hôtel downfall slip came it and who while'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(double_lstm, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be overcome lived How flung to inquire ankles burghers survived “ must Derbyshire seemed rather handsome Doubtless 361 sent a tendency? If it. Betterment in those intimately canine wounded perpetual fighting 11 double men five paper presented to ever wanted kind to ask Zachary Whether abnormally lagged radicals copse'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(single_gru, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог\n",
    "В результате мы получили 4 нейронных сети с рекуррентными слоями различных архитектур и посмотрели на то, как каждая из них генерирует последовательности слов и можем оценить насколько сгенерированные последовательности похожи на те, которые производит человек."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
